{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning -- Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review -- Regression (Linear)**\n",
    "\n",
    "* X  matrix with  n  rows (observations) and  m  columns (predictors)\n",
    "  * $x_{i,j}$  are all numbers; categorical or binary predictors are coded to numbers\n",
    "* y  matrix  (n√ó1)  with observed values\n",
    "* Choose model form -- determines the model parameters (coefficients) to be learned\n",
    "* We studied a linear model with a choice of  $X_j$ variables \n",
    "* For a single choice of model and variables, algorithm chooses the coefficients that minimize an error function \n",
    "  * Typical error function is  MSE , which is a function of actual versus predicted values\n",
    "* Search through the space of possible models (combination of variables) and choose the one that minimizes test error\n",
    "* Estimate test error through split/train/test, or cross-validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression vs. Classification, Intuitively\n",
    "\n",
    "* The response variable is **categorical** \n",
    "  * The possible categories is predefined -- {true, false}, {red, yellow, blue}\n",
    "    * The categories are not *ordered*\n",
    "* Regression prediction problem is \n",
    "  * \"predict what $y$ value will this $\\vec{x}$ have\n",
    "* Classification prediction problem is \n",
    "  * \"predict what category will this $\\vec{x}$ be in\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src=\"classification_vs_regression.png\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "---\n",
    "<img src=\"bayesian_decision_boundary.jpeg\" width=\"500\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can We Solve the Classification Problem Using Least-Squares Regression?\n",
    "\n",
    "For example\n",
    "* Patient comes in with some symptoms and some medical history\n",
    "* Predict which of \n",
    "  * 1 = stroke\n",
    "  * 2 = drug overdose\n",
    "  * 3 = seizure\n",
    "  \n",
    "* Customer applies for a loan with application and some credit history\n",
    "* Predict which of\n",
    "  * 0 = will not default\n",
    "  * 1 = default\n",
    "  \n",
    "Does it look like a regression problem?\n",
    "Would it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Models for Classification\n",
    "\n",
    "Conceptually the classification problem divides into\n",
    " * **Estimation**:  Estimate the probability $Pr(Y=y_i \\mid X=x_j)$\n",
    " * **Choice**:  To make a prediction for $x_j$ decide which $y_i$ to predict based on the estimation\n",
    " \n",
    "Estimating $Pr(Y\\mid X)$ is the hard estimation problem -- the classification models we will study all do so in a different way.\n",
    "\n",
    "But the choice problem is straightforward, at least if the goal is to minimize the *test error rate* defined as follows\n",
    "\n",
    "$$Ave(I(y_i \\neq d(x_i))$$\n",
    "where $I(v) == 1$ if $v$ is true and $0$ if $v$ is false. \n",
    "\n",
    "(That is just the average number of \"misses\" in the test set.)\n",
    "\n",
    "For this definition of error rate, the policy of choosing the $y_j$ with the \n",
    "*maximum* value for $Pr(Y=y_j\\mid X=x_i)$ minimizes the error rate.\n",
    "\n",
    "#### Emphasis on how we assess model accuracy\n",
    "\n",
    "*  Remember, model accuracy just compares observed vs predicted for *some* data set\n",
    "*  Regression minimizes MSE\n",
    "*  Classification minimized classification error\n",
    "  * Can be / usually is the percentage of the observed that were correctly predicted\n",
    "  * Or some other error metric if for example false positives are much more \"expensive\" than false negatives\n",
    "---\n",
    "#### Now on to thinking about models\n",
    "* Those that learn function parameters that provide $Pr(Y|X)$ values (logistic regression)\n",
    "  * Logistic regression is a parametric model just like linear regression except it computes probabilities for the $y$ values, not a numeric response variable\n",
    "* Tree- and Rule-based models (decision trees, deterministic decision rules, association rules)\n",
    "* Those that learn the probabilities without a parametric model (K Nearest Neighbors)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
